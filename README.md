# ðŸ¦œ LangChain Q&A Agent with Custom Gemini LLM

A clean question-answer agent built with **LangChain framework** using a custom Gemini LLM wrapper that has exactly 3 methods. This implementation uses proper LangChain agent orchestration with ReAct pattern for dynamic tool selection.

## âœ¨ Features

- **ðŸ¦œ LangChain Framework** - Proper agent orchestration using AgentExecutor
- **ðŸ§  Custom 3-Method Gemini LLM** with exactly these operations:
  - `text_to_text()` - Basic text completion
  - `text_to_json()` - Structured JSON responses  
  - `text_to_function_call()` - Function calling capabilities
- **ðŸ¤– ReAct Agent Pattern** - Reasoning and acting with tools
- **âš¡ Dynamic Tool Selection** - Automatic tool orchestration
- **ðŸ”§ LangChain Tools** - Properly integrated tools

## ðŸ› ï¸ Tools Available

- ðŸ” **Web Search** - DuckDuckGo internet search
- ðŸ§® **Calculator** - Mathematical operations
- ðŸ“… **Date/Time** - Current date and time information

## ðŸ—ï¸ Clean Project Structure

```
langchain_gemini_agent/
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ custom_gemini.py      # Custom 3-method Gemini LLM
â”‚   â”œâ”€â”€ langchain_adapter.py  # LangChain LLM adapter
â”‚   â”œâ”€â”€ schemas.py            # JSON schemas
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ web_search.py         # DuckDuckGo search tool
â”‚   â”œâ”€â”€ calculator.py         # Math operations tool
â”‚   â”œâ”€â”€ datetime_tool.py      # Date/time tool
â”‚   â”œâ”€â”€ langchain_tools.py    # LangChain tool wrappers
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ langchain_agent.py    # LangChain agent with ReAct
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ main.py                   # CLI interface
â”œâ”€â”€ requirements.txt          # Dependencies
â””â”€â”€ README.md                 # This file
```

## ðŸš€ Quick Start

1. **Install dependencies**:
```bash
pip install -r requirements.txt
```

2. **Set your Gemini API key**:
```bash
# Create a .env file
echo "GEMINI_API_KEY=your_actual_gemini_api_key" > .env
```

3. **Run the LangChain agent**:
```bash
python main.py
```

## ðŸ’¡ Example Interactions

### **Simple Questions**
```
â“ User: "What is 2 + 2?"
ðŸ¤– Agent: Uses calculator tool â†’ "Result: 4"
```

### **Web Search**
```
â“ User: "What is the current Bitcoin price?"
ðŸ¤– Agent: Uses web search â†’ Current price information
```

### **Complex Multi-Tool**
```
â“ User: "Current Bitcoin price and what's 10% of that amount"
ðŸ¤– Agent: 
  1. Searches for Bitcoin price
  2. Extracts the price value
  3. Calculates 10% using calculator
  4. Provides comprehensive answer
```

## ðŸ§  Custom LLM Architecture

### **3-Method Constraint**
The `CustomGeminiLLM` wrapper implements exactly these methods:

```python
class CustomGeminiLLM:
    def text_to_text(self, prompt: str) -> str:
        """Basic text completion with 1-second rate limiting"""
        
    def text_to_json(self, prompt: str, schema: dict) -> dict:
        """Structured JSON response with schema validation"""
        
    def text_to_function_call(self, prompt: str, functions: List[dict]) -> dict:
        """Function calling in Vertex AI style"""
```

### **LangChain Integration**
The `LangChainGeminiAdapter` wraps the custom LLM to work with LangChain:

```python
class LangChainGeminiAdapter(LLM):
    def _call(self, prompt: str, **kwargs) -> str:
        """LangChain-compatible interface"""
        return self.custom_llm.text_to_text(prompt)
```

## ðŸ¤– Agent Behavior

### **ReAct Pattern**
The agent follows the Reasoning-Acting pattern:

1. **Thought** - Analyze what needs to be done
2. **Action** - Select appropriate tool
3. **Observation** - Process tool results
4. **Final Answer** - Provide comprehensive response

### **Tool Selection Logic**
- Automatic tool selection based on question analysis
- Proper error handling and fallback
- Context preservation between tool calls

## ðŸ”§ Technical Details

### **Rate Limiting**
- 1-second sleep between Gemini API calls
- Prevents API quota exhaustion

### **Error Handling**
- Graceful tool failure handling
- Parse error recovery in LangChain
- User-friendly error messages

### **Tool Integration**
- LangChain-compatible tool wrappers
- Proper input validation with Pydantic
- Structured tool responses

## ðŸ“‹ Dependencies

- `langchain>=0.1.0` - Main framework
- `langchain-core>=0.1.0` - Core LangChain components
- `langchain-community>=0.0.10` - Community tools
- `google-generativeai>=0.3.0` - Gemini API
- `duckduckgo-search>=4.0.0` - Web search
- `python-dotenv>=1.0.0` - Environment variables
- `pydantic>=2.0.0` - Data validation

## ðŸŽ¯ Key Advantages

### **Clean Architecture**
- âœ… **Minimal Dependencies** - Only essential files
- âœ… **Separation of Concerns** - Clear module boundaries
- âœ… **Maintainable Code** - Simple, focused components
- âœ… **Easy Testing** - Modular design

### **LangChain Benefits**
- âœ… **Proper Agent Orchestration** - Built-in agent patterns
- âœ… **Tool Management** - Standardized tool interface
- âœ… **Error Handling** - Robust error recovery
- âœ… **Extensibility** - Easy to add new tools

### **Custom LLM Benefits**
- âœ… **Rate Limiting** - Built-in API protection
- âœ… **3-Method Constraint** - Simplified interface
- âœ… **Structured Outputs** - Reliable JSON responses
- âœ… **Function Calling** - Tool parameter extraction

## ðŸ”’ Security

- **Safe Calculations** - AST-based expression evaluation
- **Input Validation** - Pydantic schema validation
- **API Protection** - Rate limiting and error handling
- **No Code Execution** - Safe tool implementations

## ðŸŽª Use Cases

- **Research Assistant** - Web search + calculations
- **Financial Analysis** - Price lookup + percentage calculations  
- **General Q&A** - Mixed tool usage based on question type
- **Educational Tool** - Math problems with current data

## ðŸ§¹ Clean Implementation

This project has been thoroughly cleaned to include only:
- **Essential files** for the LangChain agent
- **Custom 3-method Gemini LLM** implementation
- **Core tools** (web search, calculator, datetime)
- **No legacy code** or unused components

The result is a minimal, maintainable codebase focused on the core functionality. 